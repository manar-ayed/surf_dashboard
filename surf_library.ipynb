{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a3c00b3f-b3a9-4afb-8244-0c7cdeea04e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Ajouter le chemin du répertoire de la bibliothèque\n",
    "sys.path.append(os.path.abspath(\"C:/Users/LENOVO/Desktop/EDS/Programmation/project/surf_scrap\"))\n",
    "\n",
    "# importer la bibliothèque\n",
    "from meteo_surf_scrap import extract_meteo_surf\n",
    "\n",
    "#csv_file = extract_meteo_surf('https://www.surf-report.com/meteo-surf/lacanau-s1043.html')\n",
    "#print(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b5deefe0-7621-48df-9e53-ae4514bc31be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_meteo_surf(url) :\n",
    "    \n",
    "    \"\"\"\n",
    "    This function takes a  url an user_agent, scrapes surf forecast data from a given url page and stores \n",
    "    data points in a csv_file\n",
    "    \n",
    "    - output : pandas dataframe contaning the data extracted\n",
    "    \"\"\"\n",
    "    \n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    \n",
    "    # Initialize empty lists to hold the data needed :\n",
    "    dates = []\n",
    "    hours = []\n",
    "    vagues = []\n",
    "    wind_speeds = []\n",
    "    wind_directions = []\n",
    "\n",
    "    # Looping through each forecast-tab block (each block represents one day)\n",
    "    forecast_tabs = soup.find_all('div', class_='forecast-tab')\n",
    "    for tab in forecast_tabs:\n",
    "        # Extracting the date for this tab\n",
    "        date_div = tab.find('div', class_='title')\n",
    "        forecast_date = date_div.find('b').text.strip() if date_div else 'N/A'\n",
    "\n",
    "        # Extracting the hours, waves, wind speeds, and wind directions for this date\n",
    "        time_divs = tab.find_all('div', class_='cell date with-border')\n",
    "        for time_div in time_divs:\n",
    "            hour = time_div.text.strip()\n",
    "            hours.append(hour)\n",
    "            dates.append(forecast_date)  # Repeat the date for each hour\n",
    "\n",
    "        # Extracting waves (vagues)\n",
    "        for wave_div in tab.find_all('div', class_='cell large waves with-border'):\n",
    "            vague = wave_div.text.strip()\n",
    "            vagues.append(vague)\n",
    "\n",
    "        # Extracting wind speeds\n",
    "        for wind_div in tab.select('div[class^=\"wind wind-color-\"]'):\n",
    "            wind_speed = wind_div.find('span').text.strip()\n",
    "            wind_speeds.append(wind_speed)\n",
    "\n",
    "        # Extracting wind directions\n",
    "        for wind_dir_div in tab.find_all('div', class_='wind img'):\n",
    "            wind_direction = wind_dir_div.find('img')['alt'] if wind_dir_div else 'N/A'\n",
    "            wind_directions.append(wind_direction)\n",
    "\n",
    "    # Creating a DataFrame with the extracted data\n",
    "    df = pd.DataFrame({\n",
    "        'Date': dates,\n",
    "        'Hour': hours,\n",
    "        'Vagues': vagues,\n",
    "        'Wind Speed (km/h)': wind_speeds,\n",
    "        'Wind Direction': wind_directions\n",
    "    })\n",
    "\n",
    "    df.to_csv('output.csv', index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b0691b82-21ea-4fbd-91b1-518d15e28259",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--input_url INPUT_URL]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\LENOVO\\AppData\\Roaming\\jupyter\\runtime\\kernel-871f0796-264c-43f3-8759-4c8b9ed4eff8.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "def main():\n",
    "    # Create the parser\n",
    "    parser = argparse.ArgumentParser(description='Extract surf forecast data from a given URL.')\n",
    "\n",
    "    # Add the URL argument\n",
    "    parser.add_argument('--input_url', type=str, help='The URL of the surf forecast page to scrape.')\n",
    "\n",
    "    # Parse the arguments\n",
    "    args = vars(parser.parse_args())\n",
    "    extract_meteo_surf(url=args[\"input_url\"])\n",
    "    \n",
    "    # Display a message indicating successful completion\n",
    "    print(\"Data extracted and saved to output.csv\")\n",
    "    print(df.head())  # Optionally print the first few rows of the DataFrame\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Call the main function with the provided URL\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e0d9463f-11a8-4225-ba16-26e38529390d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: run_surf_scrap_library.py [-h] [--input_url INPUT_URL]\n",
      "\n",
      "Extract surf forecast data from a given URL.\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  --input_url INPUT_URL\n",
      "                        The URL of the surf forecast page to scrape.\n"
     ]
    }
   ],
   "source": [
    "!python run_surf_scrap_library.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fd6ada79-0f89-4721-a86a-a1e6d04fa3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Date   Hour  ... Wind Speed (km/h)                Wind Direction\n",
      "0  Samedi 16 Novembre  01:00  ...                19          Orientation vent Est\n",
      "1  Samedi 16 Novembre  04:00  ...                23  Orientation vent Est Sud Est\n",
      "2  Samedi 16 Novembre  07:00  ...                20  Orientation vent Est Sud Est\n",
      "3  Samedi 16 Novembre  10:00  ...                14  Orientation vent Est Sud Est\n",
      "4  Samedi 16 Novembre  13:00  ...                 4      Orientation vent Sud Est\n",
      "\n",
      "[5 rows x 5 columns]\n",
      "Data extracted and saved to output.csv\n"
     ]
    }
   ],
   "source": [
    "!python run_surf_scrap_library.py --input_url \"https://www.surf-report.com/meteo-surf/lacanau-s1043.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64ce542-297f-4374-8d1b-e933017bce3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
